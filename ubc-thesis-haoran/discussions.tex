%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Discussion}
\label{ch:Discussions}

In this thesis, we aim to achieve the goal of finding a common representation of metadata that is easily interpretable, and augmenting tables with additional metadata tags to make the tables more searchable and understandable.

In this chapter, a list of questions we would like to be answered are:
\begin{enumerate}
\item How to make augmentation of topics computationally feasible? How to reduce computation for summarization, schema matching, semantic labelling? In other words, how to scale up in terms of number of tables and table size?
\item How to make the augmented topics adhere more closely to real world scenarios? How to only augment topics that the user is interested in?
\item How concise should the tags and topics be, in order to generate useful metadata?
\item How to develop an approach that generalizes to data instances with different characteristics? Every data instance has its own characteristics, some are easier to work with to generate metadata, while others are not.	
\end{enumerate}

To address the question of how to make augmentation of tags computationally feasible, we would like to revisit the idea of placing the communication step at an early step of the algorithm. By our assumption that each table already contains some useful metadata, and there is a base table to guide how to choose related tables, we developed an iterative approach to discover new information between a large number of tables. Our description of the iterative approach raised the need to find related tables so that we can compare their tags with the base table tags. We proposed to use overlapping of existing tags to approximate relatedness between tables, which reduces the cost of schema matching on the full set of tables each with many attributes in the repository. Computing the tag overlaps between two data instances is simple, but the cost is not negligible when the repository contains too many tables. We intend to replace or improve this costly step as future work.

We also discussed partitioning as an alternative to clustering to find groups of similar attributes or tags. Our implementation of the partitioning step in Improved Iterative is not efficient, and the total runtime of the algorithm is much higher than Brute Force. One reason is that we used additional matching criteria which were omitted in Brute Force. But since Brute Force has an exponential upper bound and Improved Iterative has a polynomial upper bound, we think the benefit of Improved Iterative is only apparent when we have more test sets available.

We also observed that by saving all intermediate computation steps, including the similarity matrix of schema matching and the semantic labels, we saved around one minute of time by reusing them in subsequent test runs.

To address the question of how to make the augmented tags adhere more closely to real world scenarios, we would like to revisit the design of semantic labeling. By performing word sense disambiguation using metadata contexts, we are able to attach semantics to attributes and tags. A machine can then interpret these metadata as if a human is understanding every attribute and tag. Rather than comparing a sequence of characters, a matching criterion can find the semantic distance between words, and we are able to create connectivity within a table metadata by semantic labeling between attributes and tags. In some scenarios, semantics and domain knowledge is not required, because an algorithm does not rely on it. As discussed in \cite{Yu2006Schema}, they only relied on existing links between elements to summarize groups of similar elements, these links do not provide semantics to the elements but can specify how they are related. In \cite{LI200049}, they performed clustering of elements based on data distributions of features without knowing what data they are working with.

A human would naturally try to find relationships as they read data from different sources, they could then group similar items together or discover their differences. In the same way, we use multiple matching criteria to determine similarity and differences between attributes and tags from different sources. By creating a partition for a group of similar attributes and tags, we are able to access them all at the same time, and discover new information between the attributes and tags. In our case, we know from which data instance each attribute comes from, and whether every data instance uses the same tag to describe its data. A human tends to only extract information that he or she finds useful, and any incorrect information may be tolerable as long as there is enough information extracted. In the same way, we augment the metadata in a pay-as-you-go approach, such that only data related to a base table is extracted from a repository. It is possible that the iterative method finds some incorrect metadata, but the quality of metadata can be improved over time as more information becomes available. A user may also prefer to choose whether to maximize precision or recall in the augmented metadata. Although both are important for a high quality output, it is difficult to achieve both. It is possible to let a user specify whether precision or recall is desired in a schema matching output before the algorithm is run \cite{Duchateau2009YAM}. Their algorithms would then adjust to meet the user's preference.

To address the question of how concise the tags and topics should be in order to generate useful metadata, we revisit the idea of summarization and its computational complexity. We first limited the vocabulary of the tags to reduce computation costs, no new tags are generated when an algorithm is run. We also made sure that by the end of an algorithm, all the related tables have reached a consensus on the tags representation (all the related tables have a same set of tags). The common representation permits a user or a program to search and filter by these tags. We may also relate the layout of our metadata to an autoencoder \cite{kipf2017semisupervised}, where the tags are the hidden layer in the neural network. This hidden layer is initially meaningless, but as we observe more data, the tags start to reach a common representation that can correctly represent similarities between the tables (and the attributes). We argue that the tags play an important role in many common complex problems. By creating a common representation of tag words that machines can understand, and process these words just like symbols without the need to understand the semantics.

We are unable to address the fourth question since we have not experimented on non-tabular data. However, we note that we can always create abstractions and break down large problems into smaller tasks, list a number of existing methods that were used to study other problems that can solve our tasks, and identify the changes that need to be made to solve our tasks. For each type of data, users usually tackle their problem from an engineering perspective, and explain how metadata augmentation works for their own data. However, we encourage users to think how to convert their data to tabular format, just like how we converted JSON data to CSV format. They are then able to reuse our algorithms by only making small changes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion of the iterative approach}
\label{sec:DiscussionOfTheIterativeApproach}

\subsection{Semantic enrichment discussion}

As a future extension, instead of only attaching the definition of a word, a more robust way is to attach all of its synonyms. In \cite{Giunchiglia2005Semantic}, words of each attribute name are enriched with all of its synonyms and these synonyms are connected through disjunctions. Such attachment allows the authors to perform logic programming. Since every Lemma in a Synset are synonyms of each other, we should be able to create a context for a word using information of the synonyms in addition to the information of the word itself.

Words in WordNet can be organized into a hierarchy, where hypernyms of a word are located above the word in the hierarchy. These hypernyms are the parents of the word. On the other hand, a word can be the hypernym of other words. Then these other words are the daughters of the hypernym. The sisters of a word are located in the same level in the hierarchy and share a common parent. We note that synonyms of a word can be the daughters or sisters of the word, and we may run into the issue of adding too much unrelated information of the synonyms to the context. In data exploration literature \cite{10.14778/3021924.3021935}, two modalities of drilling down data are horizonal and vertical. Horizontal exploration explores data that are the sisters, and vertical data exploration explores data that are the daughters. For example, one sense of the word $park$ is \textit{`a piece of open land for recreational use in an urban area'}. Its synonyms are commons and green, and they could be the sisters or the daughter of park. They argued that more related information are found by exploring the daughters than in the sisters. We therefore leave the experiment of adding synonyms as future work.

As another improvement, we can include adjectives to the context because overlaps in adjectives may also contribute to word sense disambiguation. We also intend to count the number of non-overlapping words, and select the word sense with the least number of non-overlapping words. The impact of selecting non-overlapping words will also be assessed as future work.

\subsection{Semantic labeling discussion}

We explain how semantic labeling is related to existing data integration techniques. In our work, since a tag can be shared across multiple tables, all the tags act like a mediated schema, where we use semantic labeling between metadata tags and schema attributes to maintain the semantic similarity across different tables. The semantic labeling acts as a source description. Assuming that there is a mediated schema that contains all possible mediated attributes, it is then easier to integrate all the schemata together. Integrated data also allows one to ask questions on a global mediated schema without the need to understand the individual local schemata.

An application of using mediated schema in matching was proposed \cite{DBLP:journals/pvldb/ChanialDGLNM18}, they used an attribute dictionary to perform instance matching. The dictionary is a knowledge base that stores attributes and its representative values, as well as probabilities of these values. The final matching between a pair of tables is determined transitively through the dictionary. The matching between a pairs of elements involve matching to the dictionary first, then an algorithm for solving the max-flow problem was used to find the best matching.

\subsection{Table search discussion}

The main idea of table searching to reduce the search space. Techniques that can reduce the search space include source selection \cite{Dong2012Proceedings}, partitioning \cite{Moawed2018Arabian}, and blocking \cite{Mudgal2018Deep}. In source selection, each table in the repository is retrieved one-by-one or in small batches, in the order from the most similar to the least. Partitioning place similar pairs of elements into the same partition, and perform further operations at each partition separately \cite{10.1145/1066157.1066283}. Blocking is a technique to reduce the number of comparisons, by eliminating pairs of elements that are highly dissimilar in the early stage \cite{Ehrig2004QOM}.

We only used source selection to reduce the search space. One of the challenges for table search is that the order in which a table is selected affects the quality of the matching, especially if only a small subset is selected. A similar issue has been addressed in \cite{Dong2012Proceedings}. In previous works, for sources with overlapping information, greedy algorithms were proposed to answer queries \cite{10.1145/1951365.1951414}. These algorithms greedily select sources, and return approximate answers quickly. There are also tools that produces a ranked list of schema in decreasing order of relatedness to the query table \cite{DBLP:conf/sigmod/ChenMH09}. In our case, if the greedy algorithm is ineffective, and the selected candidate tables are unrelated, we are unable to find the right metadata tags to augment. Since relatedness is typically approximated, and do not necessarily reflect the true relatedness, we need to make sure that our measure of relatedness is close enough to the true relatedness. We also mentioned that the table search we implement is done in an iterative manner, which reduces the chance of missing related tables, which we will explain in our main algorithm in \autoref{sec:IterativeApproach}.

\subsection{Partitioning discussion}
\label{ssec:PartitioningDiscussion}

There is a number of advantages of partitioning over clustering. When hierarchical clustering is performed, each attribute can only appear in one cluster. When we perform partitioning, it is possible to assign an attribute to multiple partitions. When we allow an attribute to be assigned to multiple partitions, similar partitions contain similar attributes (and thus indicating that the two partitions should be merged). Assigning an attribute to multiple partitions overcomes the limiting constraint discussed in \autoref{ssec:UsingSchemaMatchingOnOpenData}, so that now each attribute can be labeled with multiple tags. Furthermore, partitioning will save computation time, since every attribute-to-topic label is only examined once, unlike clustering where multiple iterations are needed.

One advantage of clustering over partitioning is that it allows a holistic view of all schemata at the same time. By performing multiple iterations of comparisons, clusters can change composition, whereas partitioning is only done in one iteration and comparisons are at a limited scope.

As an extension of the current partitioning method, we can merge or split partitions if needed, but we leave these operations as future work. If there is enough evidence that two partitions are highly similar, then we can merge them. On the other hand, if we discover that there are two or more distinctive groups of attributes in a partition, then we split the partition. We also note that when the semantic labeling is incorrect, the attribute is labeled with a wrong tag, then we need additional procedures to find the correct partition for the attribute. We will briefly revisit this idea when we discuss our main algorithm in \autoref{ssec:FutureWorkForTheAlgorithm}.

When only attribute-to-attribute correspondences is provided, an alternative approach to clustering is to perform schema merging \cite{Pottinger2008Schema}, where we take the union of all the correspondences using the known attribute overlaps to generate a mediated schema. We can then use the generated mediated schema to create topics, and semantic labeling.

We next discuss summarization and how it relates to partitioning. In a summary generation problem, complex and scattered data (such as unstructured text) is summarized and presented in a more compact and organized format (such as a list of topic words). When data is stored in a more organized format, such as tabular data. A table column can contain numeric values, symbols, acronyms, symbols describing a state or a classification, or sentences. Since tabular data is more discrete in nature, we cannot use the summary generation methods on natural language.

Many methods were invented for specific data domains and formats, and many generalized methods were also invented for understanding and organizing data in any domain \cite{Park2015Evaluation}. We made the assumption that we already know what types of metadata the user considers interesting, in our case, it is the tags in each data instance. Therefore we leave the generalized method as future work, and as we have limited the scope of our study, we only use existing tags in the open data repository as the summary of data instances. When we perform partitioning of the attributes and topics, we place similar items in the same partition, and the resulting partitions become the summary after we choose one representative example from each partition. The partitions are then used to create the semantic labeling as our algorithm output, which we will explain in \autoref{ssec:FromPartitionsToMetadataTags}. We also note that in \cite{Diego2018Machine}, the algorithm outputs both the schema matchings as well as an additional ontology. The ontology is able to provide more context to the user to understand the matchings. In our case, the output semantic labeling from our algorithm can immediately be transformed to the summary metadata tags, and the tags is intuitive for the user to understand.

\subsection{Future work for the algorithm}
\label{ssec:FutureWorkForTheAlgorithm}

The iterative approach uses the base table to find other related tables, and relatedness of tables are assessed by tag overlaps. After one table is compared with the base table and tags are added to the partitions, the next table selected related table can have tag overlap with either the original base table tags or the newly added ones. This is because we update the base table state $S$ to include the newly added tags. At the end of the iterative method, the base table as well as all the related tables are augmented with tags. We are able to achieve this because we keep track of which table an attribute is from, and we also keep the attribute-tag semantic labeling created during the initialization step, knowing both allows us to add back the augmented tags to the table.

The initialization step produces a set of semantic labels, where each attribute is labeled zero of more tags, and it is possible to transfer the tags back to the tables without running the iterative method. But we cannot be sure that these tags are correct, since the semantic labeling created are mappings between attributes and tags within one table only, it is not certain that a tag used in one table is also used for the same purpose in another table. There is no knowledge of which tables contain these tags and how the tables use the tags to describe the data. We may also miss many tags due to the limited power of semantic labeling, this justifies the need of table search, where we find tables sharing common tags, and extend with additional tags that were not already in each table. Unlike Data Driven, which can only augment a limited number of new tags, this approach can augment as many tags as possible. We need to perform schema matching to allow each table to communicate with other tables and verify whether all the tables agree with the tags vocabulary.

The iterative method replaces the full-scale schema matching done by Brute Force, reducing the total computation time of augmenting metadata. Schema matching to compare between every pair of attributes between each pair of tables is reduced to only comparing the base table with its related tables. Instead of matching attributes between schemata immediately, we compare the tags from the semantic labeling first. We use the tags as the mediator to find similar attributes, because the number of tags is often less than the number of attributes, and the tags is from a controlled vocabulary which is more representative than the attributes. In \cite{Moawed2018Arabian}, the initialization involves computing a LSH hashing index, and their table search uses this index to quickly locate similar set of attributes from tables, which allows them to compare these attributes. Compared to our initialization step and table search, we are also trading off correctness for speed. But we argue that the semantic labeling created from metadata tags increase the recall and precision of the augmented tags, even though we did not perform full-scale schema matching. During table search, we use tags to guide which pair of tables to compare, after adding related tags to the base table partitions (which increase precision), we then use these tags to find more similar tables in an iterative manner (which increase recall) until there are no more tag overlaps.

The iterative method terminates because we remove the tags (added to the base table partitions) from the selected related table during each iteration. We do not intend to select the same tables in future iterations because of the same tag overlaps, if the same tables are found to be similar in a future iteration, it is because of tag overlaps for tags not already added to the base table partitions. To give an example, tables $A$ and $B$ are found to be unrelated in an early iteration due to the lack of tag overlaps, but after more tags from table $C$ are added to $A$ in a later iteration, tables $A$ and $B$ are now found to be related because of the tag overlap between the new tags added from $C$, which $B$ shares. As the number of tag overlaps decreases between the base table and any table from the repository, the iterative method terminates once no more related tables can be found. Numerous termination conditions can be implemented as future work, such as terminating because no new tags or too few tags are added in the last iteration. In \cite{Nargesian2018Table}, they ended table search when $k$ tables are found, we can terminate in a similar way when $k$ new tags are added to the partitions. We can also terminate because a specified maximum number of iterations is reached.

We will improve the Partition step as future work as described below. The purpose of the iterative method is to make incremental changes at each iteration, and when it terminates, the incorrectness left in the partitions is minimized. We should first be able to remove a tag from a partition if it does not belong in that partition. For example, \textit{Park} has mistakenly added \textit{infrastructure} to one of its partitions, but we later find that the tag \textit{infrastructure} is used in a different context as seen in \textit{DrainageCatchBasins}, because \textit{DrainageCatchBasins} contains the tag in its original metadata whereas \textit{Park} does not. We should then remove the \textit{infrastructure} tag from the partitions. Similarly, we need to remove attributes from a partition when an attribute that was added previously no longer belongs in the partition as additional attributes are added. By SchemaMatching, we can also determine if there are any attribute not similar to the other attributes in the partition. The second operation in the improvement is splitting of a partition. We can perform clustering within a partition to find two or more groups of distinct tags, and we can split the partition based on the groups. However, the choice of a clustering algorithm to use is yet to be determined. We can similarly add a merge operation. The third improvement is to add an attribute not mapped with any tags to a partition. We compare the attribute with every attribute in every partition to find a suitable partition for the attribute. However, we think all of the above operations require additional number of comparisons with attributes and tags, and we need to find efficient algorithms to achieve these operations. One possible improvement is to avoid comparisons between every pair of items in a partition when an attribute or a tag is to be added, we compare with a representative example in the partition instead.

We also propose improvements for SchemaMatching within the iterative methods. We propose to add two measures, \textit{importance} and \textit{coverage}, to assess the similarity of a candidate tag. Importance is a measure for how many attributes are mapped with the candidate tag. In the case of comparing a base table with a related table, if many attributes in the base table can be mapped with the related table candidate tag, then the tag has high importance. We can decide to create a new partition for the candidate tag. Coverage is a measure for the number of partitions that the candidate tag could be placed in. If many tags from different partitions are similar to candidate tag, then it has high coverage. We can unconventionally decide to add the tag to multiple partitions. Other improvements of SchemaMatching include adding additional matching criteria to improve the quality of the similarity scores.

\subsection{Future work for the improved algorithm}

The FastText schema matching criterion is inadequate for computing similarity scores. We quickly compared the performance of FastText with WordNet, and found that WordNet is more likely to output true positives. Thus we used WordNet for both word sense disambiguation and schema matching and did not use word vectors to compute semantic distances.

As an extension, we can add additional schema matching criteria to provide additional evidence for accepting or rejecting a pair of items. We would like to add an extension to WordNet, where we use domain-specific knowledge bases or ontologies to perform word sense disambiguation and to find semantic distance between pairs. An ontology helps identify existing relationships among attributes and tags, because each concept has properties, and we can verify the semantic distance between concepts by the similarity of their properties. However, this work needs to be done collectively by many data experts. In \cite{Sorrentino2011NORMS}, they faced the issue of too many acronyms, abbreviations, or out-of-vocabulary words in their data. They performed normalization of the words by looking up knowledge bases available on the Internet, and replaced the words in question with known words.

Another matching criterion we may use is instance-level matching. When comparing a pair of attributes, we compare the column values each containing a list of unique values. We can then adopt the approach in \cite{Nargesian2018Table} to find attribute unionability. To speed up comparison, we can aggregate all the unique values of an attribute $A_s$ into a document and compare a pair of documents using NLP techniques discussed in \autoref{ssec:VariationsOfSchemaMatching}. For example, we can combine the values [\textit{`HartnellPark',`BettyHuffPark',`BlackieSpit',\ldots}] into\\ \textit{`HartnellPark,BettyHuffPark,BlackieSpit,\ldots'}, and compare it with another document. However, most NLP techniques relied on the sentence structure within documents, and these techniques are less powerful for our data due to the lack of full sentences in the column values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future work for experiments}
\label{sec:FutureWorkForExperiments}

Many experiments that we intend to perform are left as future work. We would like to give more analysis to why Improve Iterative has a high runtime. To achieve this, we monitor the progress of each iteration in the iterative method, and measure the accuracy and runtime after each iteration. We would also like to the measure the four algorithms with tests of larger $k$, use a variety of tables as the base table, and evaluate for different domains other than the park domain. We also need to create the gold standard for these different domains.

We noticed that many of the tags augmented by an algorithm are not present in the gold standard, but some tags are somewhat related to the base table. We could choose to add these somewhat related tags in the gold standard and rerun our test. But we could also choose to incorporate these tags into the accuracy calculation. We find the semantic distance between these somewhat related tags and the tags in the gold standard, take the maximum distance score between a pair, and add the score towards the accuracy of the test. We expect the precision to increase for all algorithms.

We only performed offline evaluation, but a good evaluation method needs to measure both the humans ability to understand the data and machine's ability to interpret the data. By performing offline evaluation, we only addressed machine interpretability. We will address the goal of improving human's ability to understand the augmented tags via user studies. We provide the repository, the tags, and a questionnaire to a number of participants, and assess their ability to answer the questions about the data when augmented tags are provided.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Usefulness of augmented metadata tags}
\label{sec:UsefulnessOfAugmentedMetadataTags}

Augmented metadata provides more interpretability to the tables through a common representation shared between multiple tables. For example, the tags in \autoref{fig:example-park-specimen-trees} were augmented, and the augmented set is shown in \autoref{fig:augmented-park-specimen-trees}. The tag overlap between \autoref{fig:example-parks} and \autoref{fig:augmented-park-specimen-trees} becomes [\textit{parks, environment, green, and nature}]. After we increase the tag overlaps between metadata of tables, searching, filtering, and explaining becomes easier for the user and machine programs.

When performing searching for similar tables, the user provides a list of tags as the query, and compare each table in the repository. The metadata of each table is compared with the query, if there are many tag overlaps between the query and the metadata of the table, then it is highly likely that the table instance contains information the user wants. For example, if the user provides \textit{parks} OR \textit{trees} as the query, then the metadata in \autoref{fig:example-parks} overlaps in [\textit{parks}] and the augmented metadata in \autoref{fig:augmented-park-specimen-trees} overlaps in [\textit{parks, trees}]. The two tables now overlap in [\textit{parks}], whereas the original metadata in \autoref{fig:example-park-specimen-trees} only overlaps in [\textit{trees}] and the two tables overlap in nothing. When performing filtering, the query becomes \textit{parks} AND \textit{trees}, and the table in \autoref{fig:augmented-park-specimen-trees} is in the results while the table in \autoref{fig:example-park-specimen-trees} is not. Finally, the augmented metadata can also help explain what information the table contains. We first examine the metadata of a table, and compare it with metadata of another table. If the two tables share many similar tags, then it is highly likely that they also share many similar data. When a user sees the augmented tags in \autoref{fig:augmented-park-specimen-trees} and \autoref{fig:example-parks}, the user can understand that both tables store information related to \textit{parks} in the urban area.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Augmented metadata helping other problems}
\label{sec:AugmentedMetadataHelpingOtherProblems}

We discuss a number of downstream data management tasks that benefit from our augmented metadata tags, with the focus on how topic extraction can help speed up data integration. High-quality augmented tags for each table are helpful in an end-to-end data-to-knowledge pipeline. In a data warehouse ETL pipeline, users and machines can easily consolidate related data instances by using tags to search tables and filter tables, and perform operations on the tables that are related to each other in the result of search. Data lakes are storage systems that simply store the data without thinking about the data being stored. There are existing works on preprocessing the data, identifying anomalies, before the data is stored. If tags are available for preprocessing, then they can help detect semantic similarities between data instances, and help grouping similar data together before storing them. In data integration, users can more easily create mediated schema for a repository of heterogenous schemata if they can use tags to group similar tables together, and create mediated attributes for each group of related attributes.

As we have mentioned, the augmented metadata tags are a summary of the data instance. But we have not considered finding the smallest set of tags that can describe the data instance well. Let the set of metadata be \textit{Parks(environment, green, nature, parks), ParkSpecimenTrees(trees, parks, environment), ParkScreenTrees(parks)} and \textit{DrainageCatchBasins(devices, infrastructure)}. Suppose the following pairs of tags are highly similar: \textit{environment} and \textit{nature}, \textit{green} and \textit{trees}, \textit{parks} and \textit{environment, parks} and \textit{trees}, and \textit{devices} and \textit{infrastructure}. Using our iterative approach, we would be placing similar tags in the same partition. We can then select one tag from each partition, and let these selected tags be the summary. For example, one possible summary is [\textit{parks, environment, trees, and infrastructure}].

During semantic enrichment, we have attached a Wordnet definition to each attribute and tag. The Wordnet definition allows disambiguation between homonyms having different senses. We can then integrate these attributes and tags to an ontology, and let the ontology be the metadata for the data instance. Each attribute or tag serves as a concept in the ontology, and its Wordnet definition becomes a property of the concept. Using the semantic distances between concepts, relationships can then be created. If we have enough tags to describe a data instance and know the rich interlinkages between the tags, then the ontology can substitute the data instance itself, because the ontology could be more machine-understandable and human-readable compared to the data instance.

Ontologies allow a different way of integrating data called publish-time data integration, where the data author needs to figure out the semantic overlaps of the new table with every possible existing table in the repository \cite{Diego2018Machine}. The publish-time approach contrasts with the pay-as-you-go approach in that the former pushes new data to a repository, and the latter pulls information from the repository to enhance the table that the user keeps locally. But with tag overlaps, the user could find semantic overlaps with less effort.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future improvements and extensions}
\label{sec:FutureImprovementsAndExtensions}

We have already discussed various ways we can improve our work throughout this thesis, and we will not repeat them here. We will raise only one idea that we have not discussed previously. Instead of returning one answer, an increasingly popular alternative is to return multiple answers and let the user choose which answer he or she needs. In \cite{ilprints851}, where they constructed a data integration system in a pay-as-you-go fashion, they returned a set of possible answers each with a probability attached. They relied on schema matching to create the mediated schema for the heterogeneous schemata, created a graph of attribute correspondences, and then clustered the attributes. Given the one-to-one cardinality constraint, they created different versions of the mediated schema, each with some differences in what mediated attributes are in the mediated schema and how the attributes are mapped to the mediated attributes. Using the schema matching scores between the attributes, they computed a probability for each possible mediated schema. We can adopt a similar approach to return a set of possible answers, where in each answer we augment tables with slightly different set of tags. For example, if a tag is placed in multiple partitions, and given a constraint that a tag can only be in one partition when augmenting the tags, we can create different versions of the augmented tags.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations in our approach}
\label{sec:LimitationsInOurApproach}

We have talked about the limitations of the algorithms we designed throughout this thesis, and we will not repeat them here. We would like to revisit one assumption that we made in \autoref{sec:ScopeOfImprovingMetadata}, where the user does not require the completeness of the metadata they see, and it is okay to create the augmented metadata in a pay-as-you-go fashion. We would like to relate our assumption to the open world assumption made in a data integration setting \cite{Doan2001Reconciling}. The assumption states that the answers returned by queries on data integration systems is not complete, since they do not know if there are other unintegrated sources that contain additional data. As long as the answer is consistent with respect to the existing subset of data, the user should be okay with the incompleteness. Given that our scenario is similar to theirs, we also make the open world assumption and give our best effort at augmenting metadata for each table

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related areas not addressed by metadata augmentation}
\label{sec:RelatedAreasNotAddressedByMetadataAugmentation}

We describe a number of related areas of research, and list the differences between the problems they solved and the problem we aimed to solve. An area of study in information retrieval is query answering, where the goal is to either return a precise or approximate answer (containing specified data in the tables) to a query. We did not address query answering because we only augmented the metadata without considering how a query can be answered using the data and metadata. In our iterative approach, the table search step answers the query of finding all tables related to a given table. Once we have augmented tags for tables, a simple query is to provide a list of tags to find all tables having these tags, which we can implement easily and assess the performance. But if a query is to precisely find all data in a database that satisfy a constraint, then we cannot answer the query trivially.

Within the study of information extraction, we only addressed the problem of inducing additional information using some existing information as seed. When we have tables and metadata as input, we did not create knowledge from raw data such as logs and sentences, we only improved the quality of the existing metadata. We discovered information from a pool of poorly maintained data and metadata exhibiting semantic heterogeneity. By our studies, we aimed to bridge the gap between schema matching, the study of structured data, and natural language processing, the study on unstructured data. Schema matching performs very little information extraction, but we applied more natural language processing techniques to improve the power of schema matching. At the same time, our end goal of augmenting topics resembles more to one of the goals of natural language processing. The algorithm we implemented meets this goal. By word sense disambiguation, we are able to perform schema matching more easily, which formally operated on the data, and the postprocessing at the end of the algorithm reaches the goal of augmenting metadata.

Knowledge graphs and ontologies both represent relations between individuals in the form of triples, very much like the correspondences we created in schema matching. However, the difference is that they have probabilistic information that define distributions over some structure (such as Markov logic networks), and they can perform inference on the graph with a given weighted formulae. The way that they built this graph is by entity resolution to resolve semantic uncertainty in some unstructured text, where they used different ways to collect evidence and make decisions.

We are also unable to address the task of joining tables. Once the user examines the augmented metadata and all the tables retrieved, the next task naturally is to join the tables in order to gain more insight to all of the data. Existing works on table joining aims at foreign key discovery \cite{Song2018GeoFlux}. We argue that knowing about more tags and the tag overlaps can somewhat help discover foreign keys in tables. Suppose that joinable attributes happened to be mapped to the same tag (as determined by the semantic labeling between attributes and tags), it is then possible to discover joinable attributes. However, existing works such as \cite{10.1145/3299869.3300065,10.14778/2994509.2994534} discovered joinable attributes by examining the table values only, and we do not think semantic labeling can perform better than their approach.

Lastly, we must make one distinction between schema matching, which we utilized in our work, and schema mapping \cite{Zhang2018Managing}. A matching identifies the correspondences, while mapping uses the correspondence information to produce instance-level transformations. A mapping typically occurs in a data warehousing pipeline, and involves writing a program to transform input data to output instances, guided by the rules of semantic correspondences. A program that merges two schema would transform elements in the source into elements in the merged schema, and add all entities to a new data instance. For example, if one source contains data \textit{['1']} while another source contains data \textit{['one']}, the transformation \textit{\{'1'-\textgreater 1,'one'-\textgreater 1\}} would transform data in both sources to $1$ and store them in a new data instance. In our work, we only performed schema matching.
\endinput