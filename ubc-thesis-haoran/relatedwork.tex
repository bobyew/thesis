%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Related Work}
\label{ch:RelatedWork}

Augmenting metadata is considered an ill-defined field of study because of the lack of existing literatures that directly address the problem. But there are many other fields of study that target problems similar in nature. For example, we can relate our task to data discovery, topic extraction, summary generation, and data integration. Data discovery determines whether there are interesting information in some data, which allows relating seemingly unrelated data together. In topic extraction and summary generation, the end result is a concise and compact representation of information in a data instance, which is highly similar to the augmented tags. Data integration plays important roles in creating common representation of data for different heterogeneous data instances, and combine the data from different data instances together.

Of all these problems, there are differences in the type of input data, output data, as well as intermediate steps that produces useful information. We therefore need to create abstractions of the different problems, break down large problems into smaller steps, and then identify the steps that we can reuse.

Of the four fields of study mentioned above, we first discuss data discovery in \autoref{sec:DataDiscovery}, where we specifically talk about information retrieval and table linking. We then discuss knowledge extraction and summary generation in \autoref{sec:KnowledgeExtractionAndSummaryGeneration}, where we specifically talk about topic modelling, ontology extraction, and text summarization. Finally, we talk about the various applications of data integration in \autoref{sec:DataIntegration}, and we briefly mention its relevance to data completion.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data discovery}
\label{sec:DataDiscovery}

Information retrieval studies how to use a query to search for data or metadata from a repository of documents. There are effective ways to retrieve all related data instances even if the full query is not available, or the data instances are incomplete. Typically, web search engines uses information retrieval techniques to search document indexes, document metadata, and data within the documents. In an open data repository consisting of tables, search is a feasible strategy to discover related tables \cite{Miller2018MakingOD}[31] \cite{10.14778/3229863.3240491}[32]. The work in \cite{Nargesian2018Table}[35] proposed an algorithm to retrieve top-K related tables given a query table. Other studies have encoded one document as a vector using semantic hashing \cite{Salakhutdinov2009Semantic}[42], which permits searching based on distance between two vectors. Another application of information retrieval is in library studies, where documents are archived, and studies were done to create metadata for the document \cite{Park2015Evaluation}[36] which can facilitate searching and retrieval.

Table linking is the study of finding relationships between tables, and it is possible to search by topic words to find related tables and related data in tables. In one work on data recommendation \cite{conf/esws/EllefiBDT16}[5], the data instances are linked by the combination of topics they contain, and by collaborative filtering on the topics, data instances are recommended. We will discuss this work later in this section. In a more general case, however, keyword queries are used to find answers in relevant data instances. In \cite{DBLP:journals/pvldb/ChanialDGLNM18}[6], each data instance is transformed to a graph structure, then subgraphs are matched to the keyword query, and all the matched subgraphs are merged as a single answer. In order to adopt this keyword search method, it is assumed that the query contains all the correct

keywords needed to retrieve the answer. If the user does not know all the keywords, then not all the related data instances can be found, and the answer is therefore incomplete.

We review data instance recommendation using data linking next, which we find relevant to the problem of retrieving data instances from large repositories and finding data instances with incomplete query.

\subsection{Recommendation of similar data using data linking}

We outline one way to recommend similar data instances given one data instance as the query \cite{conf/esws/EllefiBDT16}[5]. Each data instance is characterized by its textual descriptions and a set of schema-level features (such as topics) created by the data providers. To find the relatedness between two data instances, they find overlapping schema-level features by first constructing a bipartite graph between the topics and data instances. Each link between a data instance and a topic has a score indicating how well the topic describes the data instance. They then created a global topic-profiles graph to link all the data instances, such that each topic is mapped to a list of all data instances that contain the topic. They then used the global topic-profiles graph to recommend related data instances by collaborative filtering. For collaborative filtering to work, they made the assumption that the score is already known when each topic is linked to its data instance. The authors validated their approach with linked open data.

We now give an example to show how data instance recommendation works. In \autoref{fig:example-parks}, assume the topics are environment, green, nature, parks, and the scores are 0.7, 0.6, 0.6, 0.9 respectively. In \autoref{fig:example-park-specimen-trees}, assume the topic trees is related to the table by a score of 0.8, in

addition, there are topics parks and environment with scores of 0.7 and 0.6 respectively. A topic-to-table graph is constructed for each table, and then the topic-profiles graph is constructed. For example, the topic parks is mapped to table parks by 0.9, and to table park specimen trees by 0.7. Suppose that we are given a new table called park screen trees with a topic parks in its metadata with a score of 0.7. Collaborative filtering is performed, and since the tables parks, park specimen trees and park screen trees have high scores for the topic parks, both parks and park specimen trees are recommended to the new table park screen trees.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Knowledge extraction and summary generation}
\label{sec:KnowledgeExtractionAndSummaryGeneration}

When knowledge is difficult to understand, one can reduce the complexity of data by performing extraction of important information and summarization of the data. In topic modelling, topics are predicted from documents. If two documents contain related topics, it is possible to model the topical dependencies between them. In \cite{Zolaktaf2012Modeling}[52], they collected sufficient number of documents with known topical overlaps, and used an approach similar to latent Dirichlet allocation (LDA) to build a statistical model. Given a new document, it is then possible to infer topics for the document. In \cite{Nargesian2018Table}[35], topics can be extracted from academic research papers, finding new topic words from English sentences relies on pre-created templates to identify distinct concepts in the text. The metadata is then augmented with these additional topic words

If one needs to extract how the topics are related, existing literature in ontology extraction is able to find such relationships in sentence-like text data. An ontology is a collection of related concepts, each concept has a number of properties, and each concept is related to other concepts based on how many properties the concepts share \cite{cruz2005role}[11]. The concepts, properties, and

relationships together can be represented in a graph. For example, chemical reaction networks have chemicals as concept nodes, pH and decay rate of a chemical as properties of a concept, and interactions between chemicals as relationship edges. Each concept in an ontology is rich in semantics when it has many properties and relationships with other concepts. In \cite{10.1145/2396761.2398468}[27], an iterative method was proposed to extract ontological relationships from text data. Beginning with seed relationships extracted from a corpus, they iteratively induced more parent-child ISA or HASA relationships by using thesaurus to discover relationships between pair of words (or phrases) in the corpus. We note that if the document is not based on sentences, but rather on tabular data, it is difficult to apply this iterative approach.

When there are too many concepts, one would store them in a database so that information can be retrieved is a systematic way. A knowledge base is a database storing a collection of facts that can be understood and processed by humans or machines \cite{Zhang2018Managing}[49]. A knowledge base can be in many forms, such as a domain dictionary storing definitions of medical terms, an online Wikipedia repository storing facts, and a database storing employee payroll information. The purpose of knowledges bases is to enhance the reusability of the data and aid machines to interpret the data. For tables from the web exhibiting different forms of heterogeneity, it is possible to extract knowledge and construct a knowledge base. In \cite{10.1145/3183713.3183729}[47], they performed supervised learning with features such as whether the text is bold or whether caption appears below the table, to discover facts such as title and author of the table. The knowledge base constructed is a collection of these facts from the tables, and these facts can be queried.

Without any training data, it is still possible to perform topic extraction from tabular data. In \cite{Smith2011Unity}[43], they performed clustering of schema attributes, and assigned to each cluster a topic from a given vocabulary created by the community of authors. We will discuss this work in detail in \autoref{ssec:ClusteringToReduceComplexity}. We will then discuss another work that requires training data \cite{10.1145/3184558.3191601}[9] in \autoref{ssec:SupervisedLearningForSchemaLabeling}, that takes tabular data without headers as input and predicts a header for each column.
The complexity of data and metadata can be reduced by summary generation methods. In \cite{Benjamin2019Interactive}[23], heterogeneous text collections are summarized by omitting redundant and irrelevant information, they relied on user feedback to improve accuracy of the text summaries. Schema summarization summarizes the schema in the metadata \cite{Yu2006Schema}[48], the authors represented schemata as graphs and relied on foreign key dependencies and the link distance between two elements in the graph to create a less complex graph. We will discuss this work in more detail in \autoref{ssec:SchemaSummarization}.

\subsection{Clustering to reduce complexity}
\label{ssec:ClusteringToReduceComplexity}

A project on integration of data, the OpenII project \cite{Smith2011Unity}[43], proposed to perform clustering on the schema attributes of multiple schemata in the repository to find a common vocabulary for the repository. As explained in \cite{Smith2011Unity}[43], a vocabulary is created by a community of authors in advance, and each cluster of attributes is assigned a topic from the vocabulary. It is then possible to map every attribute in each cluster with the assigned topic. The input to clustering is a set of correspondences for the schemata in the repository, where each correspondence is a pair of attributes between two schemata and a similarity score, and clustering is performed with the constraint that disallows attributes from the same schema to be in one cluster. The final set of topics for the schemata becomes the summary of the entire repository. For their approach to

work, they assumed that correspondences on attributes are already available as input, and a vocabulary can be readily used for labeling each cluster, which requires contribution from a community of data experts.
We give an example for their work using slightly modified schemata in \autoref{fig:example-parks}, \autoref{fig:example-park-specimen-trees}, and \autoref{fig:example-park-screen-trees}. Let the input schemata be:

\begin{lstlisting}
Parks(park_name, location, service_classification),
ParkSpecimenTrees(location, park, tree_species), and
ParkScreenTrees(park_name, tree_species, number_of_trees)
\end{lstlisting}

where park\_name, location, etc are attributes of the Parks schema. Suppose that the schema matching output is:
\begin{lstlisting}
(Parks.park_name, ParkSpecimenTrees.park, 0.9),
(Parks.park_name, ParkScreenTrees.park_name, 0.95),
(ParkSpecimenTrees.park, ParkScreenTrees.park_name, 0.9),
(Parks.location, ParkSpecimenTrees.location, 0.95), and
(ParkSpecimenTrees.tree_species, ParkScreenTrees.tree_species, 0.8).
\end{lstlisting}

In each triple, the first two elements are matched attributes and the number is the score for the match. After performing clustering, the clusters of attributes are:
\begin{lstlisting}
1. {Parks.park\_name, ParkSpecimenTrees.park, ParkScreenTrees.park\_name},
2. {Parks.location, ParkSpecimenTrees.location},
3. {ParkSpecimenTrees.tree_species, ParkScreenTrees.tree_species},
4. {Parks.service_classification}, and
5. {ParkScreenTrees.number_of_trees}.
\end{lstlisting}
Each group is then examined to determine a common topic describing the cluster. Let the community vocabulary be {park name, park location, tree species, park classification, tree count}. Then the topic possibly assigned to each cluster is {1. park name, 2. park location, 3. tree species, 4. park classification, and 5. tree count}. The three mappings in the first cluster are:

\begin{lstlisting}
(park name, Parks.park_name),
(park name, ParkSpecimenTrees.park), and
(park name, ParkScreenTrees.park_name).
\end{lstlisting}

\subsection{Supervised learning for schema labeling}
\label{ssec:SupervisedLearningForSchemaLabeling}

We discuss a supervised learning method for predicting column header names for data instances. The column header names is a vocabulary known prior to prediction. In \cite{10.1145/3184558.3191601}[9], the column data of a table without a header is the input for a document classification problem to predict the header. They trained the classifier using column data as bag-of-words features and the column headers as the labels. The bag-of-words features for string datatype always have poor predictions, and improvements were made to create distinct types of features for string datatypes, which improved the predictions on headers.
To give an example, let the table and the header row in \autoref{fig:example-parks} be the training data. The trained classifier assigns the first column the header park name, and the other columns are also assigned the correct headers. We let \autoref{fig:example-park-specimen-trees} be the test data, each column is given to the classifier as input, and the classifier predicts a column name from {park name, location, service classification}. When the classifier is given the second column containing values such as Don Christian Park, 33M - Detention Pond, the classifier predicts the column name to be park is
name. Since the true column name is park, the prediction may or may not be correct based on how correctness is defined.
The assignable header names are only the header names available in \autoref{fig:example-parks}, and the classifier is unable to predict any other names for a given column. If many of the header names do not appear in the training data, then columns with those headers in the test set will never be predicted correctly. When the classifier tries to predict the third column of \autoref{fig:example-park-specimen-trees}, it is unable to predict the correct column name, because there is no similar column in the training data.

\subsection{Schema summarization}
\label{ssec:SchemaSummarization}

Schema summarization in \cite{Yu2006Schema}[48] help users understand complex schemata for relational and hierarchical databases by reducing the number of schema and the number of attributes per schema. The complex schemata is represented as a graph, where attributes (and values) are represented as nodes with foreign keys as links. The schemata is summarized by merging the elements and links, based on two summary quality properties: summary importance and summary coverage. The importance of an element is measured by how many other elements it influences (via foreign key dependencies, represented as links) and the element's own cardinality (i.e. the number of values in an instance). The coverage of an element is measured by the number of links it takes to traverse from itself to another element (i.e. whether the links in the summary can cover most of the graph). In each candidate summary, each element is the result of one or more merged elements in the original graph, and the aggregated importance and coverage scores of all elements in the summary is used to select the best summary. The selected summary should have the importance and coverage maximized.om the tables,

Using \autoref{fig:example-parks}, \autoref{fig:example-park-specimen-trees}, \autoref{fig:example-drainage-catch-basins}, and \autoref{fig:example-park-screen-trees}, as the example. Let the schemata be
\begin{lstlisting}
Parks(park_name, location, service_classification),
ParkSpecimenTrees(location, park, tree_species),
ParkScreenTrees(park_name, tree_species, number_of_trees), and DrainageCatchBasins(device_type, latitude, longitude, device_size).
\end{lstlisting}

Suppose we know that there is a foreign key dependency between
\begin{lstlisting}
Parks.park_name and ParkSpecimenTrees.park,
Parks.park_name and ParkScreenTrees.park_name,
Parks.location and ParkSpecimenTrees.location,
ParkSpecimenTrees.tree_species and ParkScreenTrees.tree_species.
\end{lstlisting}

According to the importance property \verb+{park_name, tree_species, location}+ are likely to be in the summary, because these elements have many links. Elements with sufficient number of links would increase the summary importance. The coverage property encourages elements that are far apart from each other to be in the summary. In this case, \verb+{DrainageCatchBasins.device_type}+ will be in the summary in addition to \verb+{park_name, tree_species, location}+, because elements from all four schemata will be in the summary. The attribute \verb+device_type+ is in the summary because the column does not have null values. For their algorithm to summarize the schemata, they assumed that the foreign keys constraints for the schemata are known, and their summaries are generated only based on the number of links between schema attributes. Our approach takes into account the semantics of the attributes to find a summary.

To evaluate the summary, the authors designed a user interface to interact with the summary, where the user is able to expand a summary element to display all original elements. The evaluation metric called the query discovery cost, is the number of user interactions counted before the user correctly formulates a correct query.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data integration}
\label{sec:DataIntegration}

When integrating data instances together to address heterogeneity, the relatedness can be found at different levels of data granularity. The general approach of data integration is to create data mappings to capture the relatedness of attributes of the schemata \cite{Lenzerini2002Data}[25]. The result of integration is a mediated schema a schema with mediated attributes, and a set of mappings where each schema has a mapping in terms of the mediated schema. The mapping, at the granularity of attributes, identifies all schema attributes that are similar to a mediated attribute. The mediated schema is a global state that maintains the similarity between the different schemata, and allow uniform access to the heterogeneous schemata. A query on the mediated schema is transformed to queries over individual data instances using the mappings, then answers from individual data instances are combined to produce the full answer.

Data mappings can be created in three different ways: local-as-view (LAV), global-as-view (GAV), and global-and-local-as-view (GLAV). The terms local refers to the individual schemata and global refers to the mediated schema, since a schema in a data instance is local relative to the mediated schema. LAV, GAV, and GLAV enforces different cardinality constraints between the schemata and the mediated schema. LAV mapping has a cardinality ofis

many-to-one between mediated schema attributes and local schema attributes. GAV mapping has a cardinality of one-to-many. GLAV mapping has a cardinality of many-to-many.

We will talk about one work of data integration \cite{Levy1996Querying}[26], where LAV mappings created for each schema act as the descriptions of the individual data instances via the mediated schema. The heterogeneity between schemata is addressed by the mediated schema and mappings with individual schemata. Using \autoref{fig:example-parks} and \autoref{fig:example-park-specimen-trees} as an example, we let the schemata be:

\begin{lstlisting}
Park(park_name, location, service_classification) and
ParkSpecimenTrees(location, park, tree_species).
\end{lstlisting}

Let the mediated schema (and its mediates attributes) be:

\begin{lstlisting}
MedSchema(park_name, location, tree_species, park_service),
\end{lstlisting}

with LAV mappings (where each attribute of a schema has a mapping with a mediated attribute):
\begin{lstlisting}
Park(park_name: park_name, location: location, service_classification: park_service),
ParkSpecimenTrees(location: location, park: park_name, tree_species: tree_species).
\end{lstlisting}
When a user issues a query such as MedSchema(park\_name), the LAV mappings show that the queries issued to the individual data instances should be Park(park\_name) and ParkSpecimenTrees(park).

\subsection{Relational-to-ontology schema mapping}

Mediated schema and data mappings can be used in a different way to address similar problems. We discuss one work that uses semantic labeling to assist in the integration of schemata in a repository \cite{Diego2018Machine}[14]. In this problem, the semantic labeling act as mappings between the individual schemata and a common ontology, and mappings are in the form of semantic labeling betweenscores of all e

ontology concepts and schema attributes. Given one new schema to be integrated into an existing repository, the algorithm maps each attribute in the schema to a concept in the ontology. The heterogeneity is resolved by two or more attributes mapping to the same concept in the ontology, which indicates that they are semantically similar.

Using the existing mapping of attributes to ontology, where each existing schema maps to one fragment of the ontology, they merged all the mapping fragments into a single network. They used this network to train a random forest mapping function that outputs a score for every concept-attribute pair. Using the function, they computed a score for every concept-attribute pair between the new schema and the concepts in the network. They then constructed a connected graph of all the concept-attribute pairs, and found a minimum cost Steiner tree with the constraint that an attribute maps to at most one concept. The mapping in the minimum cost Steiner Tree become the mapping of the new schema to the ontology. In order for their algorithm to work well, they assumed that an ontology exists, and their goal is to integrate a new schema into a repository in a pay-as-you-go approach.

Suppose that the repository contains schemata of \autoref{fig:example-parks} and \autoref{fig:example-park-specimen-trees}, with the following concept-attribute mappings:
\begin{lstlisting}
(parks, Parks.park_name),
(parks, ParkSpecimenTrees.park),
(UNKNOWN, Parks.location),
(UNKNOWN, ParkSpecimenTrees.location), and
(trees, ParkSpecimenTrees.tree_species).trib.findContro
\end{lstlisting}

Then the concepts are [parks, trees, UNKNOWN]. When the new schema is given:
ParkScreenTrees(park\_name, tree\_species, number\_of\_trees),

each of the attributes needs to be mapped to an existing concept in the ontology. The random forest classifier then assigns a score to pairs of ParkScreenTrees attribute and candidate concept. After finding a Steiner tree, the mapping is:

\begin{lstlisting}
(parks, ParkScreenTrees.park_name),
(UNKNOWN, ParkScreenTrees.number_of_trees), and
(trees, ParkScreenTrees.tree_species).
\end{lstlisting}

\subsection{Data completion}

Integrating data typically do not address the issue of missing values in data instances \cite{Miller2018MakingOD}[31], since the goal is to perform integration with the available information without modifications. On the other hand, the goal of data completion is to fill in the missing values, since obtaining knowledge is difficult with missing values. In \cite{Wilkinson2016FAIR}[46], predicting values that have never been reported by imputation worked poorly on the data, and a human-in-the-loop approach was taken. Data experts were asked to fill in a subset of missing values chosen by an algorithm that maximizes the correctness of the filled-in values. In our work, we will primarily rely on data integration, since we are limited by the lack of data experts.rk

