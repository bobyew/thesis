%% The following is a directive for TeXShop to indicate the main file
%%!TEX root = diss.tex

\chapter{Related Work}
\label{ch:RelatedWork}

Augmenting metadata is considered an ill-defined field of study because of the lack of existing literature that directly addresses the problem. But there are many other fields of study that target problems similar in nature. For example, we can relate our task to topics such as \textit{data discovery~\cite{Miller2018MakingOD}, knowledge extraction~\cite{Zhang2018Managing}, summary generation~\cite{Yu2006Schema}}, and \textit{data integration~\cite{Levy1996Querying}}. \textit{Data discovery} determines whether there is interesting information in some data, which allows relating seemingly unrelated data together. In \textit{knowledge extraction} and \textit{summary generation}, the end result is a concise and compact representation of information in a data instance, which is highly similar to the augmented tags. \textbf{\Gls{data integration}} plays important roles in creating common representation of data for different heterogeneous data instances, and in combining the data from different data instances.

Of all these problems, there are differences in the type of input data and output data, as well as intermediate steps that produce useful information. We therefore need to create abstractions of the different problems, break down large problems into smaller steps, and then identify the steps that we can reuse.

Of the four fields of study mentioned above, we first discuss \textit{data discovery} in \autoref{sec:DataDiscovery}, where we specifically talk about \textit{information retrieval} and \textit{table linking}. We then discuss \textit{knowledge extraction} and \textit{summary generation} in \autoref{sec:KnowledgeExtractionAndSummaryGeneration}, where we specifically talk about \textit{topic modelling}, \textit{ontology extraction}, and \textit{text summarization}. Finally, we talk about the various applications of \textit{data integration} in \autoref{sec:DataIntegration}, and we briefly mention its relevance to \textit{data completion}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data discovery}
\label{sec:DataDiscovery}

Information retrieval studies how to use a query to search for data or metadata in a repository of documents. There are effective ways to retrieve all related data instances even if the full query is not available, or the data instances are incomplete. Typically, web search engines use information retrieval techniques to search document indexes, document metadata, and data within the documents. In an open data repository consisting of tables, search is a feasible strategy to discover related tables \cite{Miller2018MakingOD,10.14778/3229863.3240491}. The work in \cite{Nargesian2018Table} proposed an algorithm to retrieve top-K related tables given a query table. Other studies have encoded one document as a vector using semantic hashing \cite{Salakhutdinov2009Semantic}, which permits searching based on distance between two vectors. Another application of information retrieval is in library studies, where documents are archived, and studies were done to create metadata for documents \cite{Park2015Evaluation} which can facilitate searching and retrieval.

Table linking is the study of finding relationships between tables, and it is possible to search by topic words to find related tables and related data in tables. In one work on data recommendation \cite{conf/esws/EllefiBDT16}, the data instances are linked by the combination of topics they contain; and by collaborative filtering on the topics, data instances are recommended. We will discuss this work in \autoref{ssec:RecommendationOfSimilarDataUsingDataLinking}. In a more general case, however, keyword queries are used to find answers in relevant data instances. In \cite{DBLP:journals/pvldb/ChanialDGLNM18}, each data instance is transformed to a graph structure, then subgraphs are matched to the keyword query, and all the matched subgraphs are merged as a single answer. In order to adopt this keyword search method, it is assumed that the query contains all the correct keywords needed to retrieve the answer. If the user does not know all the keywords, then not all the related data instances can be found, and the answer is therefore incomplete.

We review \textit{data instance recommendation using data linking} next, which we find relevant to the problem of retrieving data instances from large repositories and finding data instances with incomplete queries.

\subsection{Recommendation of similar data using data linking}
\label{ssec:RecommendationOfSimilarDataUsingDataLinking}

We outline one way to recommend similar data instances given one data instance as the query \cite{conf/esws/EllefiBDT16}. Each data instance is characterized by its textual descriptions and a set of schema-level features (such as topics) created by the data providers. To find the relatedness between two data instances, the authors find overlapping schema-level features by first constructing a bipartite graph between the topics and data instances. Each link between a data instance and a topic has a score indicating how well the topic describes the data instance. They then create a global topic-profiles graph to link all the data instances, such that each topic is mapped to a list of all data instances that contain the topic. They then use the global topic-profiles graph to recommend related data instances by collaborative filtering. For collaborative filtering to work, they made the assumption that the score is already known when each topic is linked to its data instance. The authors validated their approach with linked open data.

We now give an example to show how data instance recommendation works. In \autoref{fig:example-parks}, assume the topics are \textit{environment, green, nature, parks,} and with scores of 0.7, 0.6, 0.6, 0.9 respectively. In \autoref{fig:example-park-specimen-trees}, assume the topic \textit{trees} is related to the table by a score of 0.8. In addition, there are topics \textit{parks} and \textit{environment} with scores of 0.7 and 0.6 respectively. A topic-to-table graph is constructed for each table, and then the topic-profiles graph is constructed. For example, the topic \textit{parks} is mapped to table \textit{parks} by 0.9, and to table \textit{park specimen trees} by 0.7. Suppose that we are given a new table called \textit{park screen trees} with a topic \textit{parks} in its metadata with a score of 0.7. Collaborative filtering is performed, and since the tables \textit{parks}, \textit{park specimen trees} and \textit{park screen trees} have high scores for the topic \textit{parks}, both \textit{parks} and \textit{park specimen trees} are recommended for the new table \textit{park screen trees}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Knowledge extraction and summary generation}
\label{sec:KnowledgeExtractionAndSummaryGeneration}

When knowledge is difficult to understand, one can reduce the complexity of data by performing extraction of important information and summarization of the data. In topic modelling, topics are predicted from documents. If two documents contain related topics, it is possible to model the topical dependencies between them. In \cite{Zolaktaf2012Modeling}, they collected a sufficient number of documents with known topical overlaps, and used an approach similar to latent Dirichlet allocation (LDA) to build a statistical model. Given a new document, it is then possible to infer topics for the document. In \cite{Nargesian2018Table}, topics can be extracted from academic research papers, finding new topic words from English sentences relies on pre-created templates to identify distinct concepts in the text. The metadata is then augmented with these additional topic words.

If one needs to extract how the topics are related, existing literature in \textbf{\gls{ontology}} extraction is able to find such relationships in sentence-like text data. An ontology is a collection of related concepts. Each concept has a number of properties, and each concept is related to other concepts based on how many properties the concepts share \cite{cruz2005role}. The concepts, properties, and relationships together can be represented in a graph. For example, chemical reaction networks have chemicals as concept nodes; pH\footnote{Which stands for potential hydrogen and tells us how much hydrogen is in liquidsâ€”and how active the hydrogen ion is} and decay rate of a chemical are properties of a concept; and interactions between chemicals are relationship edges. Each concept in an ontology is rich in semantics when it has many properties and relationships with other concepts. In \cite{10.1145/2396761.2398468}, an iterative method was proposed to extract ontological relationships from text data. Beginning with seed relationships extracted from a corpus, they iteratively induced more parent-child ISA or HASA relationships by using a thesaurus to discover relationships between pairs of words (or phrases) in the corpus. We note that if the document is not based on sentences, but rather on tabular data, it is difficult to apply this iterative approach.

When there are too many concepts, one would store them in a database so that information can be retrieved in a systematic way. A \textbf{\gls{knowledge base}} is a database storing a collection of facts that can be understood and processed by humans or machines \cite{Zhang2018Managing}. A knowledge base can be in many forms, such as a domain dictionary storing definitions of medical terms, an online Wikipedia repository storing facts, and a database storing employee payroll information. The purpose of knowledge bases is to enhance the reusability of the data and aid machines to interpret the data. For tables from the web exhibiting different forms of heterogeneity, it is possible to extract knowledge and construct a knowledge base. In \cite{10.1145/3183713.3183729}, they performed supervised learning with features such as whether the text is bold or whether caption appears below the table, to discover facts such as the title and author of the table. The knowledge base constructed is a collection of these facts from the tables, and these facts can be queried.

Without any training data, it is still possible to perform \textit{knowledge extraction} from tabular data. In \cite{Smith2011Unity}, they performed clustering of schema attributes, and assigned to each cluster a topic from a given vocabulary created by the community of authors. We will discuss this work in detail in \autoref{ssec:ClusteringToReduceComplexity}. We will then discuss another work that requires training data \cite{10.1145/3184558.3191601} in \autoref{ssec:SupervisedLearningForSchemaLabeling}, that takes tabular data without headers as input and predicts a header for each column.

The complexity of data and metadata can be reduced by summary generation methods. In \cite{Benjamin2019Interactive}, heterogeneous text collections are summarized by omitting redundant and irrelevant information, the authors relied on user feedback to improve the accuracy of the text summaries. Schema summarization summarizes the schema in the metadata \cite{Yu2006Schema}. The authors represented schemata as graphs and relied on foreign key dependencies and the link distance between two elements in the graph to create a less complex graph. We will discuss this work in more detail in \autoref{ssec:SchemaSummarization}.

\subsection{Clustering to reduce complexity}
\label{ssec:ClusteringToReduceComplexity}

A project on integration of data, the OpenII project \cite{Smith2011Unity}, proposed to perform clustering on the schema attributes of multiple schemata in the repository to find a common vocabulary for the repository. As explained in \cite{Smith2011Unity}, a vocabulary is created by a community of authors in advance, and each cluster of attributes is assigned a topic from the vocabulary. It is then possible to map every attribute in each cluster with the assigned topic. The input to clustering is a set of correspondences for the schemata in the repository, where each correspondence is a pair of attributes between two schemata and a similarity score, and clustering is performed with the constraint that disallows attributes from the same schema to be in one cluster. The final set of topics for the schemata becomes the summary of the entire repository. For their approach to work, they assumed that correspondences on attributes are already available as input, and a vocabulary can be readily used for labeling each cluster, which requires contribution from a community of data experts.

We give an example for their work using slightly modified schemata in \autoref{fig:example-parks}, \autoref{fig:example-park-specimen-trees}, and \autoref{fig:example-park-screen-trees}. Let the input schemata be:
\begin{itemize}
	\item[] \textit{Parks}(\textit{park\_name}, \textit{location}, \textit{service\_classification}),
	\item[] \textit{ParkSpecimenTrees}(\textit{location}, \textit{park}, \textit{tree\_species}), and
	\item[] \textit{ParkScreenTrees}(\textit{park\_name}, \textit{tree\_species}, \textit{number\_of\_trees})
\end{itemize}
where \textit{park\_name}, \textit{location}, etc. are attributes of the \textit{Parks} schema. Suppose that the schema matching output is:
\begin{itemize}
	\item[] (\textit{Parks.park\_name}, \textit{ParkSpecimenTrees.park}, \textit{0.9}),
	\item[] (\textit{Parks.park\_name}, \textit{ParkScreenTrees.park\_name}, \textit{0.95}),
	\item[] (\textit{ParkSpecimenTrees.park}, \textit{ParkScreenTrees.park\_name}, \textit{0.9}),
	\item[] (\textit{Parks.location}, \textit{ParkSpecimenTrees.location}, \textit{0.95}), and
	\item[] (\textit{ParkSpecimenTrees.tree\_species}, \textit{ParkScreenTrees.tree\_species}, \textit{0.8}).
\end{itemize}

In each triple, the first two elements are matched attributes, and the number is the score for the match. After performing clustering, the clusters of attributes are:
\begin{enumerate}
	\item \{\textit{Parks.park\_name}, \textit{ParkSpecimenTrees.park}, \textit{ParkScreenTrees.park\_name}\},
	\item \{\textit{Parks.location}, \textit{ParkSpecimenTrees.location}\},
	\item \{\textit{ParkSpecimenTrees.tree\_species}, \textit{ParkScreenTrees.tree\_species}\},
	\item \{\textit{Parks.service\_classification}\}, and
	\item \{\textit{ParkScreenTrees.number\_of\_trees}\}.
\end{enumerate}

Each group is then examined to determine a common topic describing the cluster. Let the community vocabulary be \{\textit{park name}, \textit{park location}, \textit{tree species}, \textit{park classification}, \textit{tree count}\}. Then the topic possibly assigned to each cluster is \{1. \textit{park name}, 2. \textit{park location}, 3. \textit{tree species}, 4. \textit{park classification}, and 5. \textit{tree count}\}. The three mappings in the first cluster are:
\begin{itemize}
	\item[] (\textit{park name}, \textit{Parks.park\_name}),
	\item[] (\textit{park name}, \textit{ParkSpecimenTrees.park}), and
	\item[] (\textit{park name}, \textit{ParkScreenTrees.park\_name}).
\end{itemize}

\subsection{Supervised learning for schema labeling}
\label{ssec:SupervisedLearningForSchemaLabeling}

We discuss a supervised learning method for predicting column header names for data instances. The column header names is a vocabulary known prior to prediction. In \cite{10.1145/3184558.3191601}, the column data of a table without a header is the input for a document classification problem to predict the header. They trained the classifier using column data as bag-of-words features and the column headers as the labels. The bag-of-words features for string datatypes always have poor predictions, and improvements were made to create distinct types of features for \textit{string} datatypes, which improved the predictions on headers.

To give an example, let the table and the header row in \autoref{fig:example-parks} be the training data. The trained classifier assigns the first column the header \textit{park name}, and the other columns are also assigned the correct headers. We let \autoref{fig:example-park-specimen-trees} be the test data. Each column is given to the classifier as input, and the classifier predicts a column name from \{\textit{park name}, \textit{location}, \textit{service classification}\}. When the classifier is given the second column containing values such as \textit{``Don Christian Park, 33M - Detention Pond''}, the classifier predicts the column name to be \textit{park name}. Since the true column name is \textit{park}, the prediction may or may not be correct based on how correctness is defined.

The assignable header names are only the header names available in \autoref{fig:example-parks}, and the classifier is unable to predict any other names for a given column. If many of the header names do not appear in the training data, then columns with those headers in the test set will never be predicted correctly. When the classifier tries to predict the third column of \autoref{fig:example-park-specimen-trees}, it is unable to predict the correct column name, because there is no similar column in the training data.

\subsection{Schema summarization}
\label{ssec:SchemaSummarization}

Schema summarization~\cite{Yu2006Schema} helps users understand complex schemata for relational and hierarchical databases by reducing the number of schemata and the number of attributes per schema. The complex schemata are represented as a graph, where attributes (and values) are represented as nodes with foreign keys as links. The schemata are summarized by merging the elements and links, based on two summary quality properties: summary importance and summary coverage. The importance of an element is measured by how many other elements it influences (via foreign key dependencies, represented as links) and the element's own cardinality (i.e., the number of values in an instance). The coverage of an element is measured by the number of links it takes to traverse from itself to another element (i.e., whether the links in the summary can cover most of the graph). In each candidate summary, each element is the result of one or more merged elements in the original graph, and the aggregated importance and coverage scores of all elements in the summary is used to select the best summary. The selected summary should have the importance and coverage maximized.

Using \autoref{fig:example-parks}, \autoref{fig:example-park-specimen-trees}, \autoref{fig:example-drainage-catch-basins}, and \autoref{fig:example-park-screen-trees}, as the example, let the schemata be
\begin{itemize}
	\item[] \textit{Parks}(\textit{park\_name}, \textit{location}, \textit{service\_classification}),
	\item[] \textit{ParkSpecimenTrees}(\textit{location}, \textit{park}, \textit{tree\_species}),
	\item[] \textit{ParkScreenTrees}(\textit{park\_name}, \textit{tree\_species}, \textit{number\_of\_trees}), and 
	\item[] \textit{DrainageCatchBasins}(\textit{device\_type}, \textit{latitude}, \textit{longitude}, \textit{device\_size}).
\end{itemize}
Suppose we know that there is a foreign key dependency between
\begin{itemize}
	\item[] \textit{Parks.park\_name} and \textit{ParkSpecimenTrees.park},
	\item[] \textit{Parks.park\_name} and \textit{ParkScreenTrees.park\_name},
	\item[] \textit{Parks.location} and \textit{ParkSpecimenTrees.location},
	\item[] \textit{ParkSpecimenTrees.tree\_species} and \textit{ParkScreenTrees.tree\_species}.
\end{itemize}
According to the importance property \{\textit{park\_name}, \textit{tree\_species}, \textit{location}\} are likely to be in the summary, because these elements have many links. Elements with a sufficient number of links would increase the summary importance. The coverage property encourages elements that are far apart from each other to be in the summary. In this case, \{\textit{DrainageCatchBasins.device\_type}\} will be in the summary in addition to \{\textit{park\_name}, \textit{tree\_species}, \textit{location}\}, because elements from all four schemata will be in the summary. The attribute \textit{device\_type} is in the summary because the column does not have null values. For their algorithm to summarize the schemata, they assumed that the foreign key constraints for the schemata are known, and their summaries are generated only based on the number of links between schema attributes. Our approach takes into account the semantics of the attributes to find a summary.

To evaluate the summary, the authors designed a user interface to interact with the summary, where the user is able to expand a summary element to display all original elements. The evaluation metric called the \textit{query discovery cost}, is the number of user interactions counted before the user correctly formulates a correct query.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data integration}
\label{sec:DataIntegration}

When integrating data instances together to address heterogeneity, the relatedness can be found at different levels of data granularity. The general approach of data integration is to create data mappings to capture the relatedness of attributes of the schemata \cite{Lenzerini2002Data}. The result of integration is a \textbf{\gls{mediated schema}} which is a schema with mediated attributes, and a set of mappings where each schema has a mapping in terms of the mediated schema. The mapping, at the granularity of attributes, identifies all schema attributes that are similar to a mediated attribute. The mediated schema is a global state that maintains the similarity between the different schemata, and allows uniform access to the heterogeneous schemata. A query on the mediated schema is transformed to queries over individual data instances using the mappings. Then, answers from individual data instances are combined to produce the full answer.

Data mappings can be created in three different ways: local-as-view (LAV), global-as-view (GAV), and global-and-local-as-view (GLAV). The term \textit{local} refers to the individual schemata, and \textit{global} refers to the mediated schema, since a schema in a data instance is local relative to the mediated schema. LAV, GAV, and GLAV enforce different cardinality constraints between the schemata and the mediated schema. LAV mappings have a cardinality of many-to-one between mediated schema attributes and local schema attributes. GAV mappings have a cardinality of one-to-many. GLAV mappings have a cardinality of many-to-many.

We will talk about one work of data integration \cite{Levy1996Querying}, where LAV mappings created for each schema act as the descriptions of the individual data instances via the mediated schema. The heterogeneity between schemata is addressed by the mediated schema and mappings with individual schemata. Using \autoref{fig:example-parks} and \autoref{fig:example-park-specimen-trees} as an example, we let the schemata be:
\begin{itemize}
	\item[] \textit{Park}(\textit{park\_name}, \textit{location}, \textit{service\_classification}) and
	\item[] \textit{ParkSpecimenTrees}(\textit{location}, \textit{park}, \textit{tree\_species}).
\end{itemize}
Let the mediated schema (and its mediate attributes) be:
\begin{itemize}
	\item[] \textit{MedSchema}(\textit{park\_name}, \textit{location}, \textit{tree\_species}, \textit{park\_service}),
\end{itemize}
with LAV mappings (where each attribute of a schema has a mapping with a mediated attribute):
\begin{itemize}
	\item[] \textit{Park}(park\_name: \textit{park\_name}, location: \textit{location}, service\_classification: \textit{park\_service}),
	\item[] \textit{ParkSpecimenTrees}(location: \textit{location}, park: \textit{park\_name}, tree\_species: \textit{tree\_species}).
\end{itemize}
When a user issues a query such as MedSchema(\textit{park\_name}), the LAV mappings show that the queries issued to the individual data instances should be \textit{Park}(\textit{park\_name}) and \textit{ParkSpecimenTrees}(\textit{park}).

\subsection{Relational-to-ontology schema mapping}

Mediated schema and data mappings can be used in a different way to address similar problems. We discuss one work that uses semantic labeling to assist in the integration of schemata in a repository \cite{Diego2018Machine}. In this problem, the semantic labeling act as mappings between the individual schemata and a common ontology, and mappings are in the form of semantic labeling between ontology concepts and schema attributes. Given a new schema to be integrated into an existing repository, the algorithm maps each attribute in the schema to a concept in the ontology. The heterogeneity is resolved by two or more attributes mapping to the same concept in the ontology, which indicates that they are semantically similar.

Using the existing mapping of attributes to ontology, where each existing schema maps to one fragment of the ontology, the authors merged all the mapping fragments into a single network. They used this network to train a random forest mapping function that outputs a score for every concept-attribute pair. Using the function, they computed a score for every concept-attribute pair between the new schema and the concepts in the network. They then constructed a connected graph of all the concept-attribute pairs, and found a minimum cost Steiner tree with the constraint that an attribute maps to at most one concept. The mapping in the minimum cost Steiner Tree becomes the mapping of the new schema to the ontology. In order for their algorithm to work well, they assumed that an ontology exists, and their goal is to integrate a new schema into a repository in a pay-as-you-go approach.

Suppose that the repository contains schemata of \autoref{fig:example-parks} and \autoref{fig:example-park-specimen-trees}, with the following concept-attribute mappings:
\begin{itemize}
	\item[] (\textit{parks}, \textit{Parks.park\_name}),
	\item[] (\textit{parks}, \textit{ParkSpecimenTrees.park}),
	\item[] (\textit{UNKNOWN}, \textit{Parks.location}),
	\item[] (\textit{UNKNOWN}, \textit{ParkSpecimenTrees.location}), and
	\item[] (\textit{trees}, \textit{ParkSpecimenTrees.tree\_species}).
\end{itemize}

Then the concepts are [\textit{parks}, \textit{trees}, \textit{UNKNOWN}]. When the new schema is given:
\begin{itemize}
	\item[] \textit{ParkScreenTrees}(\textit{park\_name}, \textit{tree\_species}, \textit{number\_of\_trees}),
\end{itemize}
each of the attributes needs to be mapped to an existing concept in the ontology. The random forest classifier then assigns a score to pairs of ParkScreenTrees attribute and candidate concept. 
After finding a Steiner tree, the mapping is:
\begin{itemize}
	\item[] (\textit{parks}, \textit{ParkScreenTrees.park\_name}),
	\item[] (\textit{UNKNOWN}, \textit{ParkScreenTrees.number\_of\_trees}), and
	\item[] (\textit{trees}, \textit{ParkScreenTrees.tree\_species}).
\end{itemize}

\subsection{Data completion}

Integrating data typically does not address the issue of missing values in data instances \cite{Miller2018MakingOD}, since the goal is to perform integration with the available information without modifications. On the other hand, the goal of data completion is to fill in the missing values, since obtaining knowledge is difficult with missing values. In \cite{Wilkinson2016FAIR}, predicting values that have never been reported by imputation worked poorly on the data, and a human-in-the-loop approach was taken. Data experts were asked to fill in a subset of missing values chosen by an algorithm that maximizes the correctness of the filled-in values. In our work, we will primarily rely on data integration, since we are limited by the lack of data experts.
\endinput